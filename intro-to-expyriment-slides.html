<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Christophe@pallier.org" />
  <title>Introduction to Expyriment</title>
  <style type="text/css">
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="css/styles/slidy.css" />
  <script src="css/scripts/slidy.js"
    charset="utf-8" type="text/javascript"></script>
</head>
<body>
<div class="slide titlepage">
  <h1 class="title">Introduction to Expyriment</h1>
  <p class="author">
Christophe@pallier.org
  </p>
  <p class="date">May 2022</p>
</div>
<div class="slide" id="TOC">
<ul>
<li><a href="#requirements-for-this-tutorial">Requirements for this tutorial</a></li>
<li><a href="#why-expyriment">Why Expyriment?</a></li>
<li><a href="#first-example">First example</a></li>
<li><a href="#minimal-skeleton-for-an-expyriment-script">Minimal skeleton for an expyriment script</a></li>
<li><a href="#stimuli">Stimuli</a></li>
<li><a href="#simple-detection-of-visual-events">simple detection of visual events</a></li>
<li><a href="#simple-detection-of-audio-events">simple detection of audio events</a></li>
<li><a href="#simple-decision-parity-task">Simple decision (parity task)</a></li>
<li><a href="#simple-decisions-left-vs.-right">Simple decisions (left vs. right)</a></li>
<li><a href="#trial-and-block-objects"><code>Trial</code> and <code>Block</code> objects</a></li>
<li><a href="#more-complex-examples">More complex examples:</a></li>
<li><a href="#timing">Timing</a></li>
<li><a href="#other-ressources">Other ressources</a></li>
</ul>
</div>
<div id="requirements-for-this-tutorial" class="slide section level1">
<h1>Requirements for this tutorial</h1>
<ol style="list-style-type: decimal">
<li><p>A Python environment, e.g., <a href="https://www.anaconda.com/products/distribution">Anaconda Python 3</a>.</p></li>
<li><p>The <a href="https://www.expyriment.org">expyriment module</a> (check the installation instructions at <a href="https://docs.expyriment.org/Installation.html" class="uri">https://docs.expyriment.org/Installation.html</a>).</p></li>
<li><p>A local copy of <a href="https://github.com/chrplr/tutorial-expyriment.git" class="uri">https://github.com/chrplr/tutorial-expyriment.git</a>, which can obtain by by downloading this <a href="https://github.com/chrplr/tutorial-expyriment/archive/refs/heads/main.zip">zip file</a> or with git:</p>
<pre><code>  git clone https://github.com/chrplr/tutorial-expyriment</code></pre></li>
</ol>
<p>We assume that you know how to execute Python code from a command line in a terminal (see, e.g., <a href="https://www.youtube.com/watch?v=2yhcWvBt7ZE" class="uri">https://www.youtube.com/watch?v=2yhcWvBt7ZE</a>).</p>
</div>
<div id="why-expyriment" class="slide section level1">
<h1>Why Expyriment?</h1>
<p>Some psychology experiment generators:</p>
<ul>
<li><p><a href="http://psychtoolbox.org">Psychtoolbox</a> (MATLAB/Octave).</p></li>
<li><p><a href="https://www.psychopy.org">Psychopy</a> (either a Python library, or self-contained with a Builder “à la” Eprime))</p></li>
<li><p><a href="https://www.expyriment.org">Expyriment</a> (a Python library).</p></li>
</ul>
<p>Pros:</p>
<ul>
<li><p>Expyriment is cleaner and simpler than the other two (in my opinion). It promotes good programming practices (readability!).</p></li>
<li><p>It is good enough for most experiments (so far, the only task I could not program involved the presentation of two simultaneous videos).</p></li>
<li><p>The timing is fine when programmed correctly (VSYNC blocking,… See Retinotopy demo). For time critical applications, one must check timings as this is hardware/driver dependent.</p></li>
</ul>
<p>Cons:</p>
<ul>
<li><p>As it relies on Python, it is not possible to run remote on-line experiments.</p></li>
<li><p>Small user community =&gt; lack of documentation and examples on the web (yet the <a href="https://docs.expyriment.org/expyriment.html">interface</a> is very well-documented.</p></li>
<li><p>Dependency on the Python module <code>pygame 1.9.6</code> can cause problems during the installation.</p></li>
</ul>
</div>
<div id="first-example" class="slide section level1">
<h1>First example</h1>
<p>Guess what the following piece of code is meant to do:</p>
<pre><code>from expyriment import stimuli

fixation = stimuli.FixCross()
picture = stimuli.Picture(&quot;cat.png&quot;)
sound = stimuli.Audio(&quot;sentence.wav&quot;)

fixation.present()
exp.clock.wait(1000)
picture.present()
sound.present()

key, rt = exp.keyboard.wait_char()</code></pre>
</div>
<div id="minimal-skeleton-for-an-expyriment-script" class="slide section level1">
<h1>Minimal skeleton for an expyriment script</h1>
<p>To make the preceding code actually work, you need a bit of boilerplate (See <a href="https://docs.expyriment.org/Tutorial.html" class="uri">https://docs.expyriment.org/Tutorial.html</a>)</p>
<pre><code>from expyriment import design, control, stimuli

exp = design.Experiment(name=&quot;Experiment&quot;)

control.initialize(exp)

fixation = stimuli.FixCross()
picture = stimuli.Picture(&quot;cat.png&quot;)
sound = stimuli.Audio(&quot;sentence.wav&quot;)

control.start()

fixation.present()
exp.clock.wait(1000)
picture.present()
sound.present()
key, rt = exp.keyboard.wait_char(&#39; &#39;)

control.end()</code></pre>
<p>Execute this code in <code>ipython</code> (or with <code>python example_01.py</code>)</p>
<p>Note: You will need to press the space bar to quit it.</p>
</div>
<div id="stimuli" class="slide section level1">
<h1>Stimuli</h1>
<ul>
<li><p><code>experiment.stimuli</code> provides basic stimuli (circle, polygon, cross, text, sound, image…). See <a href="https://docs.expyriment.org/expyriment.stimuli.html" class="uri">https://docs.expyriment.org/expyriment.stimuli.html</a></p></li>
<li><p><code>expyriment.stimuli.extras</code> provides more advanced stimuli like Gabor pattern, DotCloud, (you need to )…</p></li>
</ul>
</div>
<div id="simple-detection-of-visual-events" class="slide section level1">
<h1>simple detection of visual events</h1>
<ol style="list-style-type: decimal">
<li><p>Download <a href="examples/simple_reaction_times/simple-detection-visual-expyriment.py">simple-detection-visual-expyriment.py</a></p></li>
<li><p>Run it, then check the results in the subfolder <code>data</code>. Note that:</p></li>
</ol>
<ul>
<li><p>there is one <code>.xpd</code> file per subject (the subject’s number is automatically incremented each time you launch the expyriment script).</p></li>
<li><p>this <code>.xpd</code> file is actually a comma-separated-values (csv) file, with additionnal information in lines starting with <code>#</code>.</p>
<p>You can import this file data in Python into a pandas dataframe using:</p>
<pre><code>pandas.read_csv(&#39;filename.xpd&#39;, comment=&#39;#&#39;)</code></pre>
<p>or in R:</p>
<pre><code>read.csv(&#39;filename.xpd&#39;, comment.char = &#39;#&#39;)</code></pre></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><p>Have a look at the source code.</p>
<p>Its core consists of:</p>
<pre><code>      target = stimuli.FixCross(size=(50, 50), line_width=4)
      blankscreen = stimuli.BlankScreen()

    for i_trial in range(N_TRIALS):
        blankscreen.present()
        waiting_time = random.randint(MIN_WAIT_TIME, MAX_WAIT_TIME)
        exp.clock.wait(waiting_time)
        target.present()
        key, rt = exp.keyboard.wait(duration=MAX_RESPONSE_DELAY)
        exp.data.add([i_trial, waiting_time, key, rt])</code></pre></li>
</ol>
</div>
<div id="simple-detection-of-audio-events" class="slide section level1">
<h1>simple detection of audio events</h1>
<ol style="list-style-type: decimal">
<li><p>Download <a href="examples/simple_reaction_times/simple-detection-audio-expyriment.py">simple-detection-audio-expyriment.py</a>, as well as the</p></li>
<li><p>Run it.</p></li>
<li><p>Compare its source code with the one of the visual version, for example with:</p>
<pre><code> meld simple-detection-visual-expyriment.py simple-detection-audio-expyriment.py</code></pre>
<p>The only essential difference is the line:</p>
<pre><code> target = stimuli.FixCross(size=(50, 50), line_width=4)</code></pre>
<p>which was changed into</p>
<pre><code> target = stimuli.Audio(&#39;click.wav&#39;)</code></pre></li>
</ol>
</div>
<div id="simple-decision-parity-task" class="slide section level1">
<h1>Simple decision (parity task)</h1>
<ul>
<li><p>Run <a href="examples/parity_decision/parity.py">parity.py</a></p></li>
<li><p>Run <a href="examples/parity_decision/parity_feedback.py">parity_feedback.py</a></p></li>
<li><p>See also <a href="examples/parity_short/really_short_exp.py">parity_short.py</a> (very nice example from expyriment’s documentation)</p></li>
</ul>
</div>
<div id="simple-decisions-left-vs.-right" class="slide section level1">
<h1>Simple decisions (left vs. right)</h1>
<p><a href="examples/left_right_detection_task/left_right_detection.py">left_right_detection.py</a></p>
</div>
<div id="trial-and-block-objects" class="slide section level1">
<h1><code>Trial</code> and <code>Block</code> objects</h1>
<p>The <code>design</code> submodule of expyriment provides <code>Trial</code> and <code>Block</code> objects to structure the experiment (Note that these objects are in no way necessary to present stimuli.)</p>
<ul>
<li><p><a href="examples/simple_reaction_times/grey-levels.py">grey-levels.py</a> illustrates the use of <code>set_factor()</code> and <code>get_factor()</code> for trials.</p></li>
<li><p><a href="examples/left_right_detection_task/left_right_center_detection.py">left_right_center_detection.py</a> q</p></li>
<li><p><a href="examples/simple_reaction_times/simple-detection-audiovisual.py">simple-detection-audiovisual.py</a></p></li>
</ul>
</div>
<div id="more-complex-examples" class="slide section level1">
<h1>More complex examples:</h1>
<ul>
<li><p><a href="examples/Posner_attention_networks_task">Posner ANT task</a></p>
<pre><code>  cd examples/Posner_attention_networks_task
  python posner_task.py</code></pre></li>
<li><p><a href="examples/lexical_decision/">Lexical Decision task</a></p>
<pre><code>  cd examples/lexical_decision
  python lexdec_v3.py stimuli.csv</code></pre></li>
<li><p><a href="examples/mental_logic_card_game/">Mental Logic Task</a>: illustrates the use of <code>stimuli.Canvas</code> to present several pictures simultaneaously)</p>
<pre><code>  cd examples/mental_logic_card_game/
  python mental_logic_card_game.py</code></pre></li>
<li><p><a href="https://github.com/chrplr/audiovis">Audiovis</a>: a general audio-visual stimuli presentation script.</p></li>
</ul>
</div>
<div id="timing" class="slide section level1">
<h1>Timing</h1>
<ul>
<li><p>Run:</p>
<pre><code>  cd examples/tearing_test
  python tearing-test.py</code></pre>
<p>If the vertical bar appears broken or moves very fast, this means that the <code>present()</code> function is not blocking on (waiting for) vertical retrace.</p>
<p>You may need to set up you video card to block on “vsync”.</p>
<p>Under Linux, if you have a nVidia GPU, you need to run <code>nvidia-settings</code>. If you have an AMD GPU:</p>
<pre><code>  sudo apt install xvattr
  echo &quot;export vblank_mode=3&quot; &gt; /etc/profile.d/radeon.sh</code></pre>
<p>See the documentation of the <code>expyriment.control.default.open_gl</code> at <a href="https://docs.expyriment.org/expyriment.control.defaults.html" class="uri">https://docs.expyriment.org/expyriment.control.defaults.html</a></p></li>
<li><p>Read https://docs.expyriment.org/Timing.html</p></li>
<li><p>We also provide a script to check duration of presetentation of a visual stimulus with a photodiode, and its synchrony with a sound:</p>
<pre><code>  cd examples/check-audio-visual-timing
  python check-audio-visual-timing.py</code></pre></li>
</ul>
</div>
<div id="other-ressources" class="slide section level1">
<h1>Other ressources</h1>
<ul>
<li><p><a href="https://github.com/expyriment/expyriment-stash" class="uri">https://github.com/expyriment/expyriment-stash</a></p></li>
<li><p><a href="https://mbroedl.github.io/cognitive-tasks-for-expyriment/" class="uri">https://mbroedl.github.io/cognitive-tasks-for-expyriment/</a></p></li>
</ul>
</div>
</body>
</html>
